{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0vl4eMbE8VJa3bXLR7D+W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NHMSudara/Brachial-Plexus-Nerve-Trunks-Recognition/blob/master/KR260_Brachial_Plexus_Nerve_Trunks_Recognition_in_Ultrasound_Images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Prerequisites**\n",
        "\n",
        "* Download Dataset: Download the dataset from the\n",
        "provided link (https://drive.google.com/file/d/1gfuDLMw8FQdBo9QTaSOSr74daS5lxA2n/view?usp=drive_link) and Locate Dataset in your Google Drive.\n",
        "\n",
        "* Connect the your Google Drive to  Google Colab and run following cells.\n",
        "\n"
      ],
      "metadata": {
        "id": "ap1p62tyzFaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /path/to/new_data.zip  # change the path"
      ],
      "metadata": {
        "id": "2UwyPii_z6B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Image Load**"
      ],
      "metadata": {
        "id": "Ir6COnWkr9fI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import os\n",
        "\n",
        "def load_data(path):\n",
        "    x = sorted(glob(os.path.join(path, \"image\", \"*.jpg\")))\n",
        "    y = sorted(glob(os.path.join(path, \"mask\", \"*.jpg\")))\n",
        "    return x, y\n",
        "\n",
        "dataset_path = \"/content/new_data\"\n",
        "train_path = os.path.join(dataset_path, \"train\")\n",
        "valid_path = os.path.join(dataset_path, \"test\")\n",
        "# Define the desired shape\n",
        "target_shape_img = [96, 96, 3]\n",
        "target_shape_mask = [96, 96, 1]\n",
        "\n",
        "train_x, train_y = load_data(train_path)\n",
        "valid_x, valid_y = load_data(valid_path)"
      ],
      "metadata": {
        "id": "-N70FO0_rpST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Image Preprocess**"
      ],
      "metadata": {
        "id": "aFfxp8L3rNmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from numpy import asarray\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def PreprocessData(img,mask,target_shape_img, target_shape_mask,path1):\n",
        "\n",
        "    print(img)\n",
        "    print(len(img))\n",
        "    # Pull the relevant dimensions for image and mask\n",
        "    m = len(img)                     # number of images\n",
        "    i_h,i_w,i_c = target_shape_img   # pull height, width, and channels of image\n",
        "    m_h,m_w,m_c = target_shape_mask  # pull height, width, and channels of mask\n",
        "\n",
        "    # Define X and Y as number of images along with shape of one image\n",
        "    X = np.zeros((m,i_h,i_w,i_c), dtype=np.float32)\n",
        "    y = np.zeros((m,m_h,m_w,m_c), dtype=np.int32)\n",
        "    index=0\n",
        "    # Resize images and masks\n",
        "    for file in img:\n",
        "        # convert image into an array of desired shape (3 channels)\n",
        "        sr = file.split('/')[5]\n",
        "        dotsplit = sr.split('.')[0]\n",
        "        sec=dotsplit.split('_')[-1]\n",
        "        fir=dotsplit.split('_')[0]\n",
        "        s=int(sec)\n",
        "        f=int(fir)\n",
        "\n",
        "        index= ((s*(f-1))+s)\n",
        "        path = os.path.join(path1, file)\n",
        "        single_img = Image.open(path).convert('RGB')\n",
        "        single_img = single_img.resize((i_h,i_w))\n",
        "        single_img = np.reshape(single_img,(i_h,i_w,i_c))\n",
        "        single_img = single_img/255\n",
        "        X[index] = single_img\n",
        "\n",
        "        # convert mask into an array of desired shape (1 channel)\n",
        "\n",
        "        single_mask_ind = mask[index]\n",
        "        path = os.path.join(path1, single_mask_ind)\n",
        "        single_mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        single_mask = cv2.resize(single_mask, dsize=(m_h, m_w), interpolation=cv2.INTER_NEAREST)\n",
        "        single_mask = asarray(single_mask)\n",
        "        single_mask = single_mask[..., tf.newaxis]\n",
        "        single_mask = np.reshape(single_mask,(m_h,m_w,m_c))\n",
        "        single_mask = (single_mask > 0)\n",
        "\n",
        "        y[index] = single_mask\n",
        "        index=index+1\n",
        "    return X, y\n",
        "\n",
        "\n",
        "\n",
        "X_train, Y_train = PreprocessData(train_x,train_y,target_shape_img, target_shape_mask, train_path)\n",
        "X_test, Y_test = PreprocessData(valid_x,valid_y,target_shape_img, target_shape_mask, valid_path)\n"
      ],
      "metadata": {
        "id": "e2_lGvQariyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Loss Function**"
      ],
      "metadata": {
        "id": "-Whubr7TtoMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "smooth = 1\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_float32 = tf.cast(y_true, tf.float32)\n",
        "    y_pred_float32 = tf.cast(y_pred, tf.float32)\n",
        "    y_true = tf.keras.layers.Flatten()( y_true_float32)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred_float32)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "Pf9yDB-7sklw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**CNN Model (Inc+ResU-Net )**"
      ],
      "metadata": {
        "id": "E253Wg9S2EMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout,Activation, Concatenate,Add, Lambda\n",
        "import joblib\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "\n",
        "img_rows = 96\n",
        "img_cols = 96\n",
        "depth = 3\n",
        "\n",
        "def block(prevlayer, a, b, pooling):\n",
        "    conva = Conv2D(a, (5, 5), activation='relu', padding='same')(prevlayer)\n",
        "    conva = BatchNormalization()(conva)\n",
        "    conva = Conv2D(b, (5, 5), activation='relu', padding='same')(conva)\n",
        "    conva = BatchNormalization()(conva)\n",
        "    if True == pooling:\n",
        "        conva = MaxPooling2D(pool_size=(2, 2))(conva)\n",
        "\n",
        "\n",
        "    convb = Conv2D(a, (3, 3), activation='relu', padding='same')(prevlayer)\n",
        "    convb = BatchNormalization()(convb)\n",
        "    convb = Conv2D(b, (3, 3), activation='relu', padding='same')(convb)\n",
        "    convb = BatchNormalization()(convb)\n",
        "    if True == pooling:\n",
        "        convb = MaxPooling2D(pool_size=(2, 2))(convb)\n",
        "\n",
        "    convc = Conv2D(b, (1, 1), activation='relu', padding='same')(prevlayer)\n",
        "    convc = BatchNormalization()(convc)\n",
        "    if True == pooling:\n",
        "        convc = MaxPooling2D(pool_size=(2, 2))(convc)\n",
        "\n",
        "    convd = Conv2D(a, (2, 2), activation='relu', padding='same')(prevlayer)\n",
        "    convd = BatchNormalization()(convd)\n",
        "    convd = Conv2D(b, (1, 1), activation='relu', padding='same')(convd)\n",
        "    convd = BatchNormalization()(convd)\n",
        "    if True == pooling:\n",
        "        convd = MaxPooling2D(pool_size=(2, 2))(convd)\n",
        "    convs = Conv2D((b*4), (1, 1), activation='relu', padding='same')(prevlayer)\n",
        "    if True == pooling:\n",
        "        convs = MaxPooling2D(pool_size=(2, 2))(convs)\n",
        "    up = concatenate([conva, convb, convc, convd])\n",
        "    return up,convs\n",
        "\n",
        "\n",
        "    return conv\n",
        "\n",
        "def res_block(x1,x2):\n",
        "  return Add()([x1,x2])\n",
        "\n",
        "\n",
        "def create_inc_resunet_model():\n",
        "    inputs = Input((img_rows, img_cols, depth))\n",
        "\n",
        "    xx1,s = block(inputs, 16, 16, False)\n",
        "    x1=res_block(xx1,s)\n",
        "\n",
        "\n",
        "    xx2,s1 = block(xx1, 32, 32, True)\n",
        "    x2=res_block(xx2,s1)\n",
        "\n",
        "\n",
        "    xx3,s2 = block(xx2, 64, 64,True)\n",
        "    x3=res_block(xx3,s2)\n",
        "\n",
        "\n",
        "    xx4,s3 = block(xx3, 128, 128, True)\n",
        "    x4=res_block(xx4,s3)\n",
        "\n",
        "\n",
        "    up1 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x4), x3], axis=3)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up1)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up2 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), x2], axis=3)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up2)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up3 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), x1], axis=3)\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up3)\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv8)\n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "inc_resunet_model=create_inc_resunet_model()\n",
        "print(\"Model created...\")\n",
        "inc_resunet_model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "ez_exCxmuBNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Train the CNN Model and save**"
      ],
      "metadata": {
        "id": "ua1yhgaD2Wh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inc_resunet_model.compile(optimizer=tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.00001,), loss=dice_loss, metrics=[dice_coef])\n",
        "model_path = os.path.join(\"files\", \"inc_resmodel.h5\")\n",
        "csv_path = os.path.join(\"files\", \"inc_reslog.csv\")\n",
        "callbacks = [\n",
        "    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "    CSVLogger(csv_path),\n",
        "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n",
        "]\n",
        "\n",
        "\n",
        "file_name = 'inc_resUNet'\n",
        "tensorboard = TensorBoard(log_dir=\"logs_{}\".format(file_name))\n",
        "\n",
        "history=inc_resunet_model.fit(X_train, Y_train, batch_size=32, epochs=20, verbose=1, shuffle=False,\n",
        "              validation_data= [X_test, Y_test],callbacks=[callbacks,tensorboard])"
      ],
      "metadata": {
        "id": "jQQGfSVGv-US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download trained model \"inc_resmodel.h5\""
      ],
      "metadata": {
        "id": "uJyPxFAM2phN"
      }
    }
  ]
}